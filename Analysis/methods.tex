\documentclass[a4paper,11pt]{article}

\usepackage{enumerate}
\usepackage[osf]{mathpazo}
\usepackage{lastpage}
\usepackage{url}
\usepackage{hyperref}
\pagenumbering{arabic}
\linespread{1.66}

\begin{document}

\begin{flushright}
Version dated: \today
\end{flushright}
\begin{center}

%Title
\noindent{\Large{\bf{Title}}}\
\bigskip
%Author
Thomas Guillerme\\href{mailto:t.guillerme@imperial.ac.uk}{t.guillerme@imperial.ac.uk}

\end{center}


\section{Selecting the two most extreme specimen (max and min)}

Getting the ranges of variation for the Procrustes.
This variation is equivalent to the range of Procrustes differences (i.e. the two skulls with the most different landmark positions in the procrustes superimposition).
Landmark difference is calculated using the spherical coordinates between each landmark for each pair of species.
The spherical coordinates are a coordinate system measured in a sphere composed of the radius ($\rho$, the euclidean distance between the two landmarks) the azimuth angle ($\phi$, the angle on the equatorial plan) and the polar angle ($\theta$, the angle measured on the polar plan).
Since we are only interested in the _magnitude_ of difference ($\rho$) regardless of the direction ($\phi$ and $\theta$) we will use only the radius below.

We calculate the to extremes (the two individuals with the most different radii) using the following simple algorithm:

 1. Calculate the radii for all $n$ landmarks between the mean Procrustes superimposition and each individual superimposition.
 2. Rank each set of $n$ radii and measure the area under the resulting curve.
 3. Select the specimen with the highest $n$ radii area. This is now the "maximum" Procrustes (i.e. the specimen with the most different shape compared to the mean).
 4. Calculate the radii for all $n$ landmarks between the "maximum" Procrustes and the remaining individual ones.
 5. Repeat step 2 and 3. The result specimen with the highest $n$ radii area is now the "minimum" Procrustes (i.e. the specimen with the most different shape compared to the "maximum" Procrustes).

These two "maximum" and "minimum" Procrustes are not the biggest/smallest, widest/narowest, etc. skulls _per se_ but rather the two extremes of the overall distribution of landmark variation ($\rho$).
Without visualisation, it actually impossible to even determine which one between the "maximum" or the "minimum" has actually the most variation.
However, since we are not interest in direction, this is totally sufficient to give us the magnitude of differences between specimens (while taking into account _all_ the landmarks the three dimensions).

This procedure can be compute with the `variation.range` function:


\section{Selecting the different partitions}

Here we select five partitions of the landmarks, four partitions correspond to four different zones of the cranium and on corresponds the rest of cranium (minus those four partitions).
Each one will be test blindly and noted from one to five (without _a priori_ knowledge of which is which).


The hypotheses we are testing are "Are the landmarks in partition X different than the ones in the rest of the skull?".
In mathematical phrasing: $H_{0}: \Theta_{0} = \Theta$ with a two-sided alternative $H_{1}: \Theta_{0} \neq \Theta$.
In other words, does the partition X varies more or less than the rest of the skull.


\section{How to test the differences per partitions?}

We can then test the difference per partitions using two aspects: the size difference and the probability of overlap.

 * The first one ranks the radii values and measures the difference in overlap between the distribution of radii of all the landmarks (minus the subset).
 This metrics gives an idea of the differences in length between the landmarks
 * The second one measures the probability that two landmarks radii comes from the same distribution.
 If the probability of overlap between the landmarks in the subset and all the landmarks is low, it indicates that the subset of landmark is different than the other landmarks.

### Size difference

To measure the overall differences in the length of the radii, we can calculate the area difference:

\begin{equation}
    \text{Area difference} = \int_{0}^{n-1} (f_{x} - f_{y})
\end{equation}

Where $n$ is minimum number of comparable landmarks and $f_{x}$ and $f_{y}$ are ranked functions (i.e. $f_{0} \geq f_{1} \geq f_{2} ...$).
If one of the functions $f_{x}$ or $f_{y}$ have $m$ elements (with $m > n$) $f^{*}_{z}$, a rarefied estimated of the function with $m$ elements is used instead.

\begin{equation}
    \int_{0}^{n-1}f^*_{z}d(z) = \frac{\sum_1^p\int f^*_{zi}}{p}
\end{equation}


Where $p$ is the number of rarefaction replicates.
$p$ is chosen based on the Silverman's rule of thumb for choosing the bandwidth of a Gaussian kernel density estimator multiplied by 1000 with a result forced to be 100 $\leq p \leq$ 1000 [@silverman1986density].

\begin{equation}
    p=\left(\frac{0.9\times \sigma_{m} }{1.34n}\right)^{-1/5}
\end{equation}

With $\sigma_{m}$ being the minimum of the standard deviation and the interquartile range of the distribution.

This allows the rarefaction algorithm to be fast but "fair" (i.e. reducing the number of re-sampling the more the distribution is homogeneous).

\section{Probability of overlap}

The Bhattacharyya Coefficient calculates the probability of overlap of two distributions [@Bhattacharyya; @Guillerme2016146].
When it is equal to zero, the probability of overlap of the distributions is also zero, and when it is equal to one, the two distributions are entirely overlapping.
It forms an elegant and easy to compute continuous measurement of the probability of similarity between two distributions.
The coefficient is calculated as the sum of the square root of the relative counts shared in $n$ bins among two distributions.

\begin{equation}
\text{Bhattacharyya Coefficient}=\sum_{i=1}^{n} \sqrt{{\sum{a_i}}\times{\sum{b_i}}}
\end{equation}

Where ${a_i}$ and ${b_i}$  are the number of counts in bin $i$ for the distributions $a$ and $b$ respectively divided by the total number of counts in the distribution $a$ and $b$ respectively.

The precision of the Bhattacharyya Coefficient is directly related to the number of bins, $n$.
If $n$ is low, the overlap will be overestimated and if $n$ is too high, the overlap will be underestimated.
We determined the number of bins using Silverman's rule of thumb which states that $n$ should be 0.9 times the minimum of the standard deviation and the interquartile range of the distribution, divided by $1.34$ times the sample size of the distribution to the negative one-fifth power (`bw.nrd0()` function in R) [@silverman1986density].

We consider two distributions to be significantly similar when their Bhattacharyya Coefficient is < 0.95.
Conversely, we consider them to be significantly different when their Bhattacharyya Coefficient is < 0.05.
Values in between these two threshold just show the probability of overlap between the distributions but are not conclusive to assess the similarity or differences between the distributions.

\section{Random test}

To test whether the landmark radii for one partition is different than the remaining ones, we can use a random test (modification from `ade4::as.randtest` [@thioulouse1997ade]).
These tests are pretty intuitive yet powerful.
The idea is to see whether the observed difference between a particular subsample (i.e. the partition) of a statistical population could be obtained by randomly sampling it from the same population.
Concretely, the test compares an observed measurement from a subsample (either the area difference or the Bhattacharyya Coeffient in our case) to the same measurement calculated from random subsamples of the same size.
It is then measure whether the observed subsample is different or not to the randomly generated ones the mean measurement (and variance) of a randomly generated sample.
We can then calculate a _p_ value to estimate whether the sample is significantly within or without the random distribution.
Because we measure the differences for a number of partitions, we need to adjust the calculated _p_ values.
In this study we used a simple Bonferonni-Holm correction (multiplying the _p_ value by the number of partitions).

Here is an example of what a random test would measure when creating a random partition.
In this case we the observed measurement to fall well within the randomly sampled distribution results.

\end{document}
